CIFAR-10 图像分类神经网络实现
项目概述
本项目实现了一个基于全连接神经网络（MLP）的CIFAR-10图像分类器，包含数据加载、预处理、模型训练、验证和测试等完整流程。代码使用纯NumPy实现，不依赖深度学习框架。

环境要求
Python 3.x
NumPy
Matplotlib
pickle
os
数据集准备
下载CIFAR-10数据集（Python版本）
将数据集解压到项目目录下的cifar-10-python/cifar-10-batches-py文件夹中
代码结构
- main.py  (包含所有功能的完整代码)
使用说明
1. 数据加载与预处理
代码会自动完成以下步骤：

加载CIFAR-10训练集和测试集
将数据归一化到[0,1]范围
对标签进行one-hot编码
自动划分20%的训练数据作为验证集
2. 超参数搜索
运行代码会自动执行超参数搜索，尝试以下组合：

学习率：[0.01, 0.001]
隐藏层维度：[128, 256]
正则化系数：[0.01, 0.001]
搜索过程会输出每种组合的验证准确率，并自动选择最佳组合。

3. 模型训练
使用最佳超参数训练模型：

训练轮数(epochs): 30
批量大小(batch_size): 64
学习率衰减: 每轮衰减5%
训练过程中会显示：

每个batch的训练损失
每个epoch结束时的验证准确率
训练和验证损失曲线
验证准确率曲线
4. 模型测试
训练完成后，代码会自动在测试集上评估模型性能，输出测试准确率。

5. 权重可视化
训练结束后，代码会可视化各层权重矩阵，帮助理解模型学习到的特征。

运行方式
直接运行主程序：

bash
复制
python main.py  
输出说明
训练过程输出:
每个epoch和batch的训练损失
每个epoch的验证准确率
最佳超参数组合
可视化输出:
训练损失 vs 验证损失曲线
验证准确率曲线
各层权重矩阵热力图
最终输出:
测试集准确率
自定义修改
修改网络结构:
在NeuralNetwork类中调整layers列表
可添加更多隐藏层或修改各层维度
调整训练参数:
修改train_model函数中的参数：
epochs: 训练轮数
batch_size: 批量大小
learning_rate: 初始学习率
扩展超参数搜索:
在hyperparameter_search函数中添加更多候选值
注意事项
训练过程可能需要较长时间（取决于硬件配置）
当前实现使用CPU计算，对于大型网络可能较慢
最终准确率受随机初始化影响，每次运行可能略有不同
预期结果
使用最佳超参数训练30个epoch后，测试集准确率通常在45-55%之间（受限于MLP结构和纯NumPy实现）。
